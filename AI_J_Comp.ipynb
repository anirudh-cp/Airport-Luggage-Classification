{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anirudh-cp/Airport-Luggage-Classification/blob/main/AI_J_Comp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6cAwgE-TdhR",
        "outputId": "335cf1fa-e589-440a-f6aa-c1dc9599e4e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.9/dist-packages (22.0.4)\n",
            "Collecting pip\n",
            "  Downloading pip-23.0.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 22.0.4\n",
            "    Uninstalling pip-22.0.4:\n",
            "      Successfully uninstalled pip-22.0.4\n",
            "Successfully installed pip-23.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oeyP0aYes9Zs",
        "outputId": "c2a2f975-7ad5-43ec-ce7e-277472790e1d"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEGpXLl3tQVX"
      },
      "source": [
        "## **Cloning TFOD 2.0 Github**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFkdXoEltLY9",
        "outputId": "c8534b80-7e2a-4741-a59a-c2781966561a"
      },
      "source": [
        "!git clone https://github.com/tensorflow/models.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 82703, done.\u001b[K\n",
            "remote: Counting objects: 100% (609/609), done.\u001b[K\n",
            "remote: Compressing objects: 100% (242/242), done.\u001b[K\n",
            "remote: Total 82703 (delta 400), reused 559 (delta 367), pack-reused 82094\u001b[K\n",
            "Receiving objects: 100% (82703/82703), 596.60 MiB | 17.40 MiB/s, done.\n",
            "Resolving deltas: 100% (59040/59040), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "aJ4YzpQ4tMlz",
        "outputId": "da394648-29db-4abf-e0b0-55f3197cdc9c"
      },
      "source": [
        "pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZwI0sTdtMsc",
        "outputId": "3c5aa941-b719-4205-b19f-e2451b284c1c"
      },
      "source": [
        "cd /content/models/research"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/research\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "SK5RyNz9tMvZ",
        "outputId": "761c6c77-ac4a-4551-bc2a-71b7c5957e98"
      },
      "source": [
        "pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/models/research'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NozH3MfAtMyR"
      },
      "source": [
        "!protoc object_detection/protos/*.proto --python_out=."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alOqL7ortM1F",
        "outputId": "f444fbb8-f554-4188-de93-ddb42b0ffa06"
      },
      "source": [
        "!git clone https://github.com/cocodataset/cocoapi.git\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'cocoapi'...\n",
            "remote: Enumerating objects: 975, done.\u001b[K\n",
            "remote: Total 975 (delta 0), reused 0 (delta 0), pack-reused 975\u001b[K\n",
            "Receiving objects: 100% (975/975), 11.72 MiB | 15.88 MiB/s, done.\n",
            "Resolving deltas: 100% (576/576), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XRlMiuEtM4R",
        "outputId": "dbc76741-70f9-4767-e226-95041af4f1df"
      },
      "source": [
        "cd cocoapi/PythonAPI"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/research/cocoapi/PythonAPI\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZ-xj6MUtM7U",
        "outputId": "0e409460-334c-45df-a1e0-d74b28e9e491"
      },
      "source": [
        "!make"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python setup.py build_ext --inplace\n",
            "running build_ext\n",
            "cythoning pycocotools/_mask.pyx to pycocotools/_mask.c\n",
            "/usr/local/lib/python3.9/dist-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /content/models/research/cocoapi/PythonAPI/pycocotools/_mask.pyx\n",
            "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
            "building 'pycocotools._mask' extension\n",
            "creating build\n",
            "creating build/common\n",
            "creating build/temp.linux-x86_64-3.9\n",
            "creating build/temp.linux-x86_64-3.9/pycocotools\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.9/dist-packages/numpy/core/include -I../common -I/usr/include/python3.9 -c ../common/maskApi.c -o build/temp.linux-x86_64-3.9/../common/maskApi.o -Wno-cpp -Wno-unused-function -std=c99\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleDecode\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:46:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "   46 |       \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; v=!v; }}\n",
            "      |       \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:46:49:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
            "   46 |       for( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; \u001b[01;36m\u001b[Kv\u001b[m\u001b[K=!v; }}\n",
            "      |                                                 \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrPoly\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:166:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "  166 |   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); x[k]=x[0];\n",
            "      |   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:166:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
            "  166 |   for(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); \u001b[01;36m\u001b[Kx\u001b[m\u001b[K[k]=x[0];\n",
            "      |                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:167:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "  167 |   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); y[k]=y[0];\n",
            "      |   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:167:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
            "  167 |   for(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); \u001b[01;36m\u001b[Ky\u001b[m\u001b[K[k]=y[0];\n",
            "      |                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleToString\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:212:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "  212 |       \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(more) c |= 0x20; c+=48; s[p++]=c;\n",
            "      |       \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:212:27:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n",
            "  212 |       if(more) c |= 0x20; \u001b[01;36m\u001b[Kc\u001b[m\u001b[K+=48; s[p++]=c;\n",
            "      |                           \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrString\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:220:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "  220 |   \u001b[01;35m\u001b[Kwhile\u001b[m\u001b[K( s[m] ) m++; cnts=malloc(sizeof(uint)*m); m=0;\n",
            "      |   \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:220:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’\n",
            "  220 |   while( s[m] ) m++; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K=malloc(sizeof(uint)*m); m=0;\n",
            "      |                      \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:228:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "  228 |     \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(m>2) x+=(long) cnts[m-2]; cnts[m++]=(uint) x;\n",
            "      |     \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:228:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n",
            "  228 |     if(m>2) x+=(long) cnts[m-2]; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K[m++]=(uint) x;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.9/dist-packages/numpy/core/include -I../common -I/usr/include/python3.9 -c pycocotools/_mask.c -o build/temp.linux-x86_64-3.9/pycocotools/_mask.o -Wno-cpp -Wno-unused-function -std=c99\n",
            "creating build/lib.linux-x86_64-3.9\n",
            "creating build/lib.linux-x86_64-3.9/pycocotools\n",
            "x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 -Wl,-Bsymbolic-functions -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.9/../common/maskApi.o build/temp.linux-x86_64-3.9/pycocotools/_mask.o -o build/lib.linux-x86_64-3.9/pycocotools/_mask.cpython-39-x86_64-linux-gnu.so\n",
            "copying build/lib.linux-x86_64-3.9/pycocotools/_mask.cpython-39-x86_64-linux-gnu.so -> pycocotools\n",
            "rm -rf build\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5Qr7ACCtM_b"
      },
      "source": [
        "cp -r pycocotools /content/models/research"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLq79dR0uQFt"
      },
      "source": [
        "### Install the Object Detection API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DM2bgHvLtNFt",
        "outputId": "14fe0fa4-5af9-4979-dd6a-5dc2fa778e0a"
      },
      "source": [
        "cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/research/cocoapi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZouxA5TuWgV",
        "outputId": "e8fa8f19-c838-41c6-d7a4-ec23a29ac3ed"
      },
      "source": [
        "cd .. "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/research\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q635Jl58uWjI"
      },
      "source": [
        "cp object_detection/packages/tf2/setup.py ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZyrPaXSxuWmI",
        "outputId": "ac9dfb86-7be9-4b6c-ac06-c11766854462"
      },
      "source": [
        "!python -m pip install ."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing /content/models/research\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting avro-python3\n",
            "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting apache-beam\n",
            "  Downloading apache_beam-2.46.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.5/14.5 MB\u001b[0m \u001b[31m80.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.9/dist-packages (from object-detection==0.1) (8.4.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.9/dist-packages (from object-detection==0.1) (4.9.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from object-detection==0.1) (3.7.1)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.9/dist-packages (from object-detection==0.1) (0.29.33)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.9/dist-packages (from object-detection==0.1) (0.6.0.post1)\n",
            "Requirement already satisfied: tf-slim in /usr/local/lib/python3.9/dist-packages (from object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from object-detection==0.1) (1.16.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.9/dist-packages (from object-detection==0.1) (2.0.6)\n",
            "Collecting lvis\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from object-detection==0.1) (1.10.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from object-detection==0.1) (1.4.4)\n",
            "Collecting tf-models-official>=2.5.1\n",
            "  Downloading tf_models_official-2.11.5-py2.py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m79.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow_io\n",
            "  Downloading tensorflow_io-0.31.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (26.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.9/dist-packages (from object-detection==0.1) (2.11.0)\n",
            "Collecting pyparsing==2.4.7\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sacrebleu<=2.2.0\n",
            "  Downloading sacrebleu-2.2.0-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.6/116.6 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.9/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (0.8.10)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.9/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (2022.10.31)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (1.22.4)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.9/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.13)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.9/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.7.0.72)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m78.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow~=2.11.0 in /usr/local/lib/python3.9/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.11.0)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.9/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n",
            "Collecting tensorflow-text~=2.11.0\n",
            "  Downloading tensorflow_text-2.11.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m79.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting immutabledict\n",
            "  Downloading immutabledict-2.2.3-py3-none-any.whl (4.0 kB)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.9/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.8.3)\n",
            "Collecting py-cpuinfo>=3.3.0\n",
            "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.19.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyyaml<6.0,>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp39-cp39-manylinux1_x86_64.whl (630 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m630.1/630.1 kB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.9/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.70.0)\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.9/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.9.4)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.13.0)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.9/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n",
            "Collecting tensorflow-model-optimization>=0.4.1\n",
            "  Downloading tensorflow_model_optimization-0.7.3-py2.py3-none-any.whl (238 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.9/238.9 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->object-detection==0.1) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->object-detection==0.1) (2.8.2)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.9/dist-packages (from tf-slim->object-detection==0.1) (1.4.0)\n",
            "Collecting zstandard<1,>=0.18.0\n",
            "  Downloading zstandard-0.20.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m83.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting objsize<0.7.0,>=0.6.1\n",
            "  Downloading objsize-0.6.1-py3-none-any.whl (9.3 kB)\n",
            "Requirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.9/dist-packages (from apache-beam->object-detection==0.1) (1.22.2)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.9/dist-packages (from apache-beam->object-detection==0.1) (1.4.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.9/dist-packages (from apache-beam->object-detection==0.1) (4.5.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /usr/local/lib/python3.9/dist-packages (from apache-beam->object-detection==0.1) (2.27.1)\n",
            "Collecting hdfs<3.0.0,>=2.1.0\n",
            "  Downloading hdfs-2.7.0-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: grpcio!=1.48.0,<2,>=1.33.1 in /usr/local/lib/python3.9/dist-packages (from apache-beam->object-detection==0.1) (1.51.3)\n",
            "Collecting pymongo<4.0.0,>=3.8.0\n",
            "  Downloading pymongo-3.13.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (515 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m515.5/515.5 kB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson<4.0\n",
            "  Downloading orjson-3.8.8-cp39-cp39-manylinux_2_28_x86_64.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fasteners<1.0,>=0.3\n",
            "  Downloading fasteners-0.18-py3-none-any.whl (18 kB)\n",
            "Collecting dill<0.3.2,>=0.3.1.1\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.0/152.0 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting crcmod<2.0,>=1.7\n",
            "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: httplib2<0.22.0,>=0.8 in /usr/local/lib/python3.9/dist-packages (from apache-beam->object-detection==0.1) (0.21.0)\n",
            "Requirement already satisfied: protobuf<4,>3.12.2 in /usr/local/lib/python3.9/dist-packages (from apache-beam->object-detection==0.1) (3.19.6)\n",
            "Requirement already satisfied: pyarrow<10.0.0,>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from apache-beam->object-detection==0.1) (9.0.0)\n",
            "Collecting fastavro<2,>=0.23.6\n",
            "  Downloading fastavro-1.7.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m95.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cloudpickle~=2.2.1 in /usr/local/lib/python3.9/dist-packages (from apache-beam->object-detection==0.1) (2.2.1)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from lvis->object-detection==0.1) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.9/dist-packages (from lvis->object-detection==0.1) (0.11.0)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.9/dist-packages (from lvis->object-detection==0.1) (4.7.0.72)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->object-detection==0.1) (1.0.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->object-detection==0.1) (23.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->object-detection==0.1) (4.39.2)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->object-detection==0.1) (5.12.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.31.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow_io->object-detection==0.1) (0.31.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.9/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.1.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.9/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.1.1)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.9/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.11.0)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=1.19.0 in /usr/local/lib/python3.9/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.16.2)\n",
            "Collecting docopt\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib->object-detection==0.1) (3.15.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.9/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2022.12.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.65.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.9/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.26.15)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.9/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (8.0.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2.0.12)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (2.11.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (23.3.3)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (15.0.6.1)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.9/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (2.11.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (3.8.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (1.15.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (67.6.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (2.2.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.8)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.9/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.9/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.9/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.2.2)\n",
            "Collecting typeguard>=2.7\n",
            "  Downloading typeguard-3.0.2-py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n",
            "Requirement already satisfied: etils[enp,epath]>=0.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.1.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (8.1.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.12.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.10.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/dist-packages (from astunparse>=1.6.0->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (0.40.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.9/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.59.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (5.3.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.1.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (3.4.3)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (2.2.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n",
            "Requirement already satisfied: importlib-metadata>=3.6 in /usr/local/lib/python3.9/dist-packages (from typeguard>=2.7->tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (6.1.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.9/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (2.1.2)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (3.2.2)\n",
            "Building wheels for collected packages: object-detection, avro-python3, crcmod, dill, seqeval, docopt\n",
            "  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1697012 sha256=abbbdc11be0463ca00884aae633b8840a1a4496af706bfe37a5afebdb1da5457\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-etam26zo/wheels/1d/d6/23/8af3ea45a1048e13ebe55b2675eecc8eb39c9af79b37e078ae\n",
            "  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=44008 sha256=1987417ccce9353d7e7f3a4406f6534579b6561346527c50488602d1a39a78fa\n",
            "  Stored in directory: /root/.cache/pip/wheels/5a/29/4d/510c0e098c49c5e49519f430481a5425e60b8752682d7b1e55\n",
            "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for crcmod: filename=crcmod-1.7-cp39-cp39-linux_x86_64.whl size=36914 sha256=80866475d1d41aca1da83626d5a2b2089f56ab64c31df0077bb401dc3daa3687\n",
            "  Stored in directory: /root/.cache/pip/wheels/4a/6c/a6/ffdd136310039bf226f2707a9a8e6857be7d70a3fc061f6b36\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78545 sha256=2bd8f01b24c5c76b6c3e15201928d07cfdd64d84f10dd20514a0ace2d881b81b\n",
            "  Stored in directory: /root/.cache/pip/wheels/4f/0b/ce/75d96dd714b15e51cb66db631183ea3844e0c4a6d19741a149\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=5837e0b24a18255d6ccc9a7f9a5e290ec6190bee0a8f39e46d5e078358419178\n",
            "  Stored in directory: /root/.cache/pip/wheels/e2/a5/92/2c80d1928733611c2747a9820e1324a6835524d9411510c142\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13721 sha256=c19b7f8a8a1184c3a339c3eac50303fab990aa7e7ab7b15b50f83dde7bdedb03\n",
            "  Stored in directory: /root/.cache/pip/wheels/70/4a/46/1309fc853b8d395e60bafaf1b6df7845bdd82c95fd59dd8d2b\n",
            "Successfully built object-detection avro-python3 crcmod dill seqeval docopt\n",
            "Installing collected packages: sentencepiece, py-cpuinfo, docopt, crcmod, zstandard, tensorflow-model-optimization, tensorflow_io, pyyaml, pyparsing, pymongo, portalocker, orjson, objsize, immutabledict, fasteners, fastavro, dill, colorama, avro-python3, typeguard, sacrebleu, hdfs, tensorflow-addons, seqeval, lvis, apache-beam, tensorflow-text, tf-models-official, object-detection\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0\n",
            "    Uninstalling PyYAML-6.0:\n",
            "      Successfully uninstalled PyYAML-6.0\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.0.9\n",
            "    Uninstalling pyparsing-3.0.9:\n",
            "      Successfully uninstalled pyparsing-3.0.9\n",
            "Successfully installed apache-beam-2.46.0 avro-python3-1.10.2 colorama-0.4.6 crcmod-1.7 dill-0.3.1.1 docopt-0.6.2 fastavro-1.7.3 fasteners-0.18 hdfs-2.7.0 immutabledict-2.2.3 lvis-0.5.3 object-detection-0.1 objsize-0.6.1 orjson-3.8.8 portalocker-2.7.0 py-cpuinfo-9.0.0 pymongo-3.13.0 pyparsing-2.4.7 pyyaml-5.4.1 sacrebleu-2.2.0 sentencepiece-0.1.97 seqeval-1.2.2 tensorflow-addons-0.19.0 tensorflow-model-optimization-0.7.3 tensorflow-text-2.11.0 tensorflow_io-0.31.0 tf-models-official-2.11.5 typeguard-3.0.2 zstandard-0.20.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjlR4lsmuWpE",
        "outputId": "2d7a0810-c4ba-4dc8-a556-5448da5743b8"
      },
      "source": [
        "# From within TensorFlow/models/research/\n",
        "!python object_detection/builders/model_builder_tf2_test.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-03-28 13:22:09.580696: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-28 13:22:09.580788: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-28 13:22:09.580807: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Running tests under Python 3.9.16: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "2023-03-28 13:22:16.244757: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "W0328 13:22:16.723527 140086597048128 model_builder.py:1112] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 3.25s\n",
            "I0328 13:22:17.181565 140086597048128 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 3.25s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 1.52s\n",
            "I0328 13:22:18.701654 140086597048128 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 1.52s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.46s\n",
            "I0328 13:22:19.161872 140086597048128 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.46s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.42s\n",
            "I0328 13:22:19.586676 140086597048128 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.42s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.08s\n",
            "I0328 13:22:21.671035 140086597048128 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.08s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "I0328 13:22:21.678816 140086597048128 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n",
            "I0328 13:22:21.703670 140086597048128 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n",
            "I0328 13:22:21.719846 140086597048128 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
            "I0328 13:22:21.736196 140086597048128 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.11s\n",
            "I0328 13:22:21.843111 140086597048128 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.11s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.26s\n",
            "I0328 13:22:22.106861 140086597048128 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.26s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.1s\n",
            "I0328 13:22:22.208324 140086597048128 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.1s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.1s\n",
            "I0328 13:22:22.304814 140086597048128 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.1s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.1s\n",
            "I0328 13:22:22.400775 140086597048128 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.1s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n",
            "I0328 13:22:22.429655 140086597048128 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "I0328 13:22:22.610663 140086597048128 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
            "I0328 13:22:22.610792 140086597048128 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 64\n",
            "I0328 13:22:22.610861 140086597048128 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 3\n",
            "I0328 13:22:22.613056 140086597048128 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0328 13:22:22.641136 140086597048128 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0328 13:22:22.641258 140086597048128 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0328 13:22:22.717023 140086597048128 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0328 13:22:22.717141 140086597048128 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0328 13:22:22.910887 140086597048128 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0328 13:22:22.911029 140086597048128 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0328 13:22:23.090828 140086597048128 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0328 13:22:23.091056 140086597048128 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0328 13:22:23.357571 140086597048128 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0328 13:22:23.357726 140086597048128 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0328 13:22:23.629763 140086597048128 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0328 13:22:23.629942 140086597048128 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0328 13:22:23.982929 140086597048128 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0328 13:22:23.983090 140086597048128 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I0328 13:22:24.073304 140086597048128 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I0328 13:22:24.115236 140086597048128 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0328 13:22:24.165672 140086597048128 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
            "I0328 13:22:24.165798 140086597048128 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 88\n",
            "I0328 13:22:24.165867 140086597048128 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 4\n",
            "I0328 13:22:24.167382 140086597048128 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0328 13:22:24.184201 140086597048128 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0328 13:22:24.184318 140086597048128 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0328 13:22:24.326899 140086597048128 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0328 13:22:24.327048 140086597048128 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0328 13:22:24.578266 140086597048128 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0328 13:22:24.578452 140086597048128 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0328 13:22:24.833424 140086597048128 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0328 13:22:24.833575 140086597048128 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0328 13:22:25.180289 140086597048128 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0328 13:22:25.180466 140086597048128 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0328 13:22:25.517371 140086597048128 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0328 13:22:25.517520 140086597048128 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0328 13:22:25.944699 140086597048128 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0328 13:22:25.944851 140086597048128 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I0328 13:22:26.115957 140086597048128 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I0328 13:22:26.147791 140086597048128 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0328 13:22:26.207305 140086597048128 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
            "I0328 13:22:26.207469 140086597048128 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 112\n",
            "I0328 13:22:26.207540 140086597048128 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 5\n",
            "I0328 13:22:26.209128 140086597048128 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0328 13:22:26.226187 140086597048128 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0328 13:22:26.226298 140086597048128 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0328 13:22:26.358989 140086597048128 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0328 13:22:26.359124 140086597048128 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0328 13:22:26.872547 140086597048128 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0328 13:22:26.872742 140086597048128 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0328 13:22:27.186181 140086597048128 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0328 13:22:27.186358 140086597048128 efficientnet_model.py:143] round_filter input=80 output=88\n",
            "I0328 13:22:27.716962 140086597048128 efficientnet_model.py:143] round_filter input=80 output=88\n",
            "I0328 13:22:27.717112 140086597048128 efficientnet_model.py:143] round_filter input=112 output=120\n",
            "I0328 13:22:28.082374 140086597048128 efficientnet_model.py:143] round_filter input=112 output=120\n",
            "I0328 13:22:28.082567 140086597048128 efficientnet_model.py:143] round_filter input=192 output=208\n",
            "I0328 13:22:28.516663 140086597048128 efficientnet_model.py:143] round_filter input=192 output=208\n",
            "I0328 13:22:28.516820 140086597048128 efficientnet_model.py:143] round_filter input=320 output=352\n",
            "I0328 13:22:28.689253 140086597048128 efficientnet_model.py:143] round_filter input=1280 output=1408\n",
            "I0328 13:22:28.725862 140086597048128 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0328 13:22:28.778962 140086597048128 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
            "I0328 13:22:28.779098 140086597048128 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 160\n",
            "I0328 13:22:28.779196 140086597048128 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 6\n",
            "I0328 13:22:28.780890 140086597048128 efficientnet_model.py:143] round_filter input=32 output=40\n",
            "I0328 13:22:28.801967 140086597048128 efficientnet_model.py:143] round_filter input=32 output=40\n",
            "I0328 13:22:28.802072 140086597048128 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0328 13:22:28.944446 140086597048128 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0328 13:22:28.944582 140086597048128 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0328 13:22:29.218646 140086597048128 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0328 13:22:29.218799 140086597048128 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0328 13:22:29.466684 140086597048128 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0328 13:22:29.466838 140086597048128 efficientnet_model.py:143] round_filter input=80 output=96\n",
            "I0328 13:22:29.928601 140086597048128 efficientnet_model.py:143] round_filter input=80 output=96\n",
            "I0328 13:22:29.928818 140086597048128 efficientnet_model.py:143] round_filter input=112 output=136\n",
            "I0328 13:22:30.548261 140086597048128 efficientnet_model.py:143] round_filter input=112 output=136\n",
            "I0328 13:22:30.548460 140086597048128 efficientnet_model.py:143] round_filter input=192 output=232\n",
            "I0328 13:22:31.284668 140086597048128 efficientnet_model.py:143] round_filter input=192 output=232\n",
            "I0328 13:22:31.284858 140086597048128 efficientnet_model.py:143] round_filter input=320 output=384\n",
            "I0328 13:22:31.538698 140086597048128 efficientnet_model.py:143] round_filter input=1280 output=1536\n",
            "I0328 13:22:31.590724 140086597048128 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0328 13:22:31.691989 140086597048128 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
            "I0328 13:22:31.692173 140086597048128 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 224\n",
            "I0328 13:22:31.692252 140086597048128 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 7\n",
            "I0328 13:22:31.694729 140086597048128 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0328 13:22:31.723963 140086597048128 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0328 13:22:31.724098 140086597048128 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0328 13:22:31.922194 140086597048128 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0328 13:22:31.922388 140086597048128 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0328 13:22:32.430160 140086597048128 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0328 13:22:32.430382 140086597048128 efficientnet_model.py:143] round_filter input=40 output=56\n",
            "I0328 13:22:32.934977 140086597048128 efficientnet_model.py:143] round_filter input=40 output=56\n",
            "I0328 13:22:32.935169 140086597048128 efficientnet_model.py:143] round_filter input=80 output=112\n",
            "I0328 13:22:33.704022 140086597048128 efficientnet_model.py:143] round_filter input=80 output=112\n",
            "I0328 13:22:33.704213 140086597048128 efficientnet_model.py:143] round_filter input=112 output=160\n",
            "I0328 13:22:34.476378 140086597048128 efficientnet_model.py:143] round_filter input=112 output=160\n",
            "I0328 13:22:34.476581 140086597048128 efficientnet_model.py:143] round_filter input=192 output=272\n",
            "I0328 13:22:35.525816 140086597048128 efficientnet_model.py:143] round_filter input=192 output=272\n",
            "I0328 13:22:35.526044 140086597048128 efficientnet_model.py:143] round_filter input=320 output=448\n",
            "I0328 13:22:35.798572 140086597048128 efficientnet_model.py:143] round_filter input=1280 output=1792\n",
            "I0328 13:22:35.857875 140086597048128 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0328 13:22:36.291499 140086597048128 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
            "I0328 13:22:36.291693 140086597048128 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 288\n",
            "I0328 13:22:36.291777 140086597048128 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 7\n",
            "I0328 13:22:36.294189 140086597048128 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0328 13:22:36.319440 140086597048128 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0328 13:22:36.319569 140086597048128 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0328 13:22:36.617012 140086597048128 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0328 13:22:36.617185 140086597048128 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0328 13:22:37.268945 140086597048128 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0328 13:22:37.269141 140086597048128 efficientnet_model.py:143] round_filter input=40 output=64\n",
            "I0328 13:22:37.823642 140086597048128 efficientnet_model.py:143] round_filter input=40 output=64\n",
            "I0328 13:22:37.823804 140086597048128 efficientnet_model.py:143] round_filter input=80 output=128\n",
            "I0328 13:22:38.455544 140086597048128 efficientnet_model.py:143] round_filter input=80 output=128\n",
            "I0328 13:22:38.455707 140086597048128 efficientnet_model.py:143] round_filter input=112 output=176\n",
            "I0328 13:22:39.072546 140086597048128 efficientnet_model.py:143] round_filter input=112 output=176\n",
            "I0328 13:22:39.072706 140086597048128 efficientnet_model.py:143] round_filter input=192 output=304\n",
            "I0328 13:22:39.853152 140086597048128 efficientnet_model.py:143] round_filter input=192 output=304\n",
            "I0328 13:22:39.853307 140086597048128 efficientnet_model.py:143] round_filter input=320 output=512\n",
            "I0328 13:22:40.130059 140086597048128 efficientnet_model.py:143] round_filter input=1280 output=2048\n",
            "I0328 13:22:40.169032 140086597048128 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0328 13:22:40.245675 140086597048128 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
            "I0328 13:22:40.245818 140086597048128 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 384\n",
            "I0328 13:22:40.245886 140086597048128 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 8\n",
            "I0328 13:22:40.247400 140086597048128 efficientnet_model.py:143] round_filter input=32 output=56\n",
            "I0328 13:22:40.272034 140086597048128 efficientnet_model.py:143] round_filter input=32 output=56\n",
            "I0328 13:22:40.272148 140086597048128 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0328 13:22:40.480690 140086597048128 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0328 13:22:40.480848 140086597048128 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0328 13:22:40.996570 140086597048128 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0328 13:22:40.996758 140086597048128 efficientnet_model.py:143] round_filter input=40 output=72\n",
            "I0328 13:22:41.528553 140086597048128 efficientnet_model.py:143] round_filter input=40 output=72\n",
            "I0328 13:22:41.528709 140086597048128 efficientnet_model.py:143] round_filter input=80 output=144\n",
            "I0328 13:22:42.231804 140086597048128 efficientnet_model.py:143] round_filter input=80 output=144\n",
            "I0328 13:22:42.231969 140086597048128 efficientnet_model.py:143] round_filter input=112 output=200\n",
            "I0328 13:22:42.945074 140086597048128 efficientnet_model.py:143] round_filter input=112 output=200\n",
            "I0328 13:22:42.945242 140086597048128 efficientnet_model.py:143] round_filter input=192 output=344\n",
            "I0328 13:22:43.919052 140086597048128 efficientnet_model.py:143] round_filter input=192 output=344\n",
            "I0328 13:22:43.919206 140086597048128 efficientnet_model.py:143] round_filter input=320 output=576\n",
            "I0328 13:22:44.452354 140086597048128 efficientnet_model.py:143] round_filter input=1280 output=2304\n",
            "I0328 13:22:44.487082 140086597048128 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0328 13:22:44.576630 140086597048128 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
            "I0328 13:22:44.576773 140086597048128 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 384\n",
            "I0328 13:22:44.576841 140086597048128 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 8\n",
            "I0328 13:22:44.578449 140086597048128 efficientnet_model.py:143] round_filter input=32 output=64\n",
            "I0328 13:22:44.597550 140086597048128 efficientnet_model.py:143] round_filter input=32 output=64\n",
            "I0328 13:22:44.597676 140086597048128 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0328 13:22:44.875818 140086597048128 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0328 13:22:44.875976 140086597048128 efficientnet_model.py:143] round_filter input=24 output=48\n",
            "I0328 13:22:45.477346 140086597048128 efficientnet_model.py:143] round_filter input=24 output=48\n",
            "I0328 13:22:45.477511 140086597048128 efficientnet_model.py:143] round_filter input=40 output=80\n",
            "I0328 13:22:46.065236 140086597048128 efficientnet_model.py:143] round_filter input=40 output=80\n",
            "I0328 13:22:46.065404 140086597048128 efficientnet_model.py:143] round_filter input=80 output=160\n",
            "I0328 13:22:46.917247 140086597048128 efficientnet_model.py:143] round_filter input=80 output=160\n",
            "I0328 13:22:46.917423 140086597048128 efficientnet_model.py:143] round_filter input=112 output=224\n",
            "I0328 13:22:47.869802 140086597048128 efficientnet_model.py:143] round_filter input=112 output=224\n",
            "I0328 13:22:47.869988 140086597048128 efficientnet_model.py:143] round_filter input=192 output=384\n",
            "I0328 13:22:49.362984 140086597048128 efficientnet_model.py:143] round_filter input=192 output=384\n",
            "I0328 13:22:49.363170 140086597048128 efficientnet_model.py:143] round_filter input=320 output=640\n",
            "I0328 13:22:49.870149 140086597048128 efficientnet_model.py:143] round_filter input=1280 output=2560\n",
            "I0328 13:22:49.922539 140086597048128 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 27.67s\n",
            "I0328 13:22:50.102555 140086597048128 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 27.67s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "I0328 13:22:50.147184 140086597048128 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "I0328 13:22:50.149864 140086597048128 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "I0328 13:22:50.150547 140086597048128 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "I0328 13:22:50.152853 140086597048128 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTF2Test.test_session\n",
            "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "I0328 13:22:50.154836 140086597048128 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "I0328 13:22:50.155491 140086597048128 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "I0328 13:22:50.159769 140086597048128 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "----------------------------------------------------------------------\n",
            "Ran 24 tests in 36.225s\n",
            "\n",
            "OK (skipped=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gL4BBRoZuWr8",
        "outputId": "6d76bf23-f094-4a64-ef70-a69d98d7b320"
      },
      "source": [
        "cd /content/training_data/pre-trained-models"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/training_data/pre-trained-models\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MItGLVY3uWu8",
        "outputId": "371a5074-c288-4986-8257-327e1ad336cf"
      },
      "source": [
        "!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-28 13:50:05--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 142.251.10.128, 2404:6800:4003:c0f::80\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|142.251.10.128|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 386527459 (369M) [application/x-tar]\n",
            "Saving to: ‘ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz’\n",
            "\n",
            "ssd_resnet101_v1_fp 100%[===================>] 368.62M  76.8MB/s    in 5.1s    \n",
            "\n",
            "2023-03-28 13:50:11 (72.0 MB/s) - ‘ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz’ saved [386527459/386527459]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzlPcDPLuWye",
        "outputId": "5447e9f0-a27a-44f9-916d-5810f28f2373"
      },
      "source": [
        "!tar -xvf ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/checkpoint/\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/checkpoint/checkpoint\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0.index\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/pipeline.config\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/saved_model.pb\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/assets/\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/variables/\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/variables/variables.index\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Vf49zVcAtNJB",
        "outputId": "6a892d19-72c1-4d86-a118-6e001285d983"
      },
      "source": [
        "pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/training_data/pre-trained-models'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFA0L4rmyGae",
        "outputId": "7b01ba80-40a4-4fe4-8714-a0a2d8c6b44c"
      },
      "source": [
        "cd /content/training_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/training_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pxst7lPT0Sby",
        "outputId": "a43583f2-b449-4b23-ea9a-35160a856be8"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mannotations\u001b[0m/         export_tflite_graph_tf2.py  model_main_tf2.py\n",
            "\u001b[01;34mexported_models\u001b[0m/     generate_tfrecord.py        \u001b[01;34mmodels\u001b[0m/\n",
            "exporter_main_v2.py  \u001b[01;34mimages\u001b[0m/                     \u001b[01;34mpre-trained-models\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hU2lVZfzyuar",
        "outputId": "892493b9-064a-4820-aadd-1f07647e10c3"
      },
      "source": [
        "# Create train data:\n",
        "!python generate_tfrecord.py -x /content/training_data/images/train -l /content/training_data/annotations/label_map.pbtxt -o /content/training_data/annotations/train.record\n",
        "\n",
        "# Create test data:\n",
        "!python generate_tfrecord.py -x /content/training_data/images/test -l /content/training_data/annotations/label_map.pbtxt -o /content/training_data/annotations/test.record"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully created the TFRecord file: /content/training_data/annotations/train.record\n",
            "Successfully created the TFRecord file: /content/training_data/annotations/test.record\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfHABHxi56kM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "9b8a328c-cfa3-4f59-9cf1-07a919ff9024"
      },
      "source": [
        "pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/training_data'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQO8P8xLy6bS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4a48bf9-47bf-46d8-d887-14eb26620362"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mannotations\u001b[0m/         export_tflite_graph_tf2.py  model_main_tf2.py\n",
            "\u001b[01;34mexported_models\u001b[0m/     generate_tfrecord.py        \u001b[01;34mmodels\u001b[0m/\n",
            "exporter_main_v2.py  \u001b[01;34mimages\u001b[0m/                     \u001b[01;34mpre-trained-models\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNVwlSCq9pr1",
        "outputId": "67872310-a5d7-443f-a79d-5966d503e621"
      },
      "source": [
        "!python model_main_tf2.py --model_dir=/content/training_data/models/my_ssd_resnet101_v1_fpn --pipeline_config_path=/content/training_data/models/my_ssd_resnet101_v1_fpn/pipeline.config"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-03-28 15:47:23.190805: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-28 15:47:23.191007: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-28 15:47:23.191036: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-28 15:47:33.138530: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "I0328 15:47:33.264675 140463426705216 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "INFO:tensorflow:Maybe overwriting train_steps: None\n",
            "I0328 15:47:33.268221 140463426705216 config_util.py:552] Maybe overwriting train_steps: None\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0328 15:47:33.268408 140463426705216 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "W0328 15:47:33.308221 140463426705216 deprecation.py:350] From /usr/local/lib/python3.9/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/training_data/annotations/train.record']\n",
            "I0328 15:47:33.328627 140463426705216 dataset_builder.py:162] Reading unweighted datasets: ['/content/training_data/annotations/train.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/training_data/annotations/train.record']\n",
            "I0328 15:47:33.328859 140463426705216 dataset_builder.py:79] Reading record datasets for input file: ['/content/training_data/annotations/train.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0328 15:47:33.328989 140463426705216 dataset_builder.py:80] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0328 15:47:33.329070 140463426705216 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "W0328 15:47:33.342700 140463426705216 deprecation.py:350] From /usr/local/lib/python3.9/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0328 15:47:33.383477 140463426705216 deprecation.py:350] From /usr/local/lib/python3.9/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
            "W0328 15:47:33.993586 140463426705216 deprecation.py:350] From /usr/local/lib/python3.9/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0328 15:47:39.798624 140463426705216 deprecation.py:350] From /usr/local/lib/python3.9/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/util/dispatch.py:1176: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W0328 15:47:42.457752 140463426705216 deprecation.py:350] From /usr/local/lib/python3.9/dist-packages/tensorflow/python/util/dispatch.py:1176: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0328 15:47:44.403683 140463426705216 deprecation.py:350] From /usr/local/lib/python3.9/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "/usr/local/lib/python3.9/dist-packages/keras/backend.py:451: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn(\n",
            "I0328 15:48:15.508077 140458426889984 api.py:459] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n",
            "I0328 15:48:26.961694 140458426889984 api.py:459] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0328 15:48:51.166081 140463426705216 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0328 15:48:51.169148 140463426705216 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0328 15:48:51.170365 140463426705216 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0328 15:48:51.171433 140463426705216 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0328 15:48:51.174883 140463426705216 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0328 15:48:51.175918 140463426705216 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0328 15:48:51.176969 140463426705216 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0328 15:48:51.178027 140463426705216 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0328 15:48:51.181578 140463426705216 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0328 15:48:51.182540 140463426705216 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "W0328 15:48:53.627938 140458602755840 deprecation.py:554] From /usr/local/lib/python3.9/dist-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "I0328 15:48:55.520490 140458602755840 api.py:459] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n",
            "I0328 15:49:06.764326 140458602755840 api.py:459] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n",
            "I0328 15:49:15.315952 140458602755840 api.py:459] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n",
            "I0328 15:49:26.121499 140458602755840 api.py:459] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n",
            "INFO:tensorflow:Step 100 per-step time 2.552s\n",
            "I0328 15:53:08.850221 140463426705216 model_lib_v2.py:705] Step 100 per-step time 2.552s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.5172635,\n",
            " 'Loss/localization_loss': 0.46121705,\n",
            " 'Loss/regularization_loss': 0.3037901,\n",
            " 'Loss/total_loss': 1.2822707,\n",
            " 'learning_rate': 0.014666351}\n",
            "I0328 15:53:08.856227 140463426705216 model_lib_v2.py:708] {'Loss/classification_loss': 0.5172635,\n",
            " 'Loss/localization_loss': 0.46121705,\n",
            " 'Loss/regularization_loss': 0.3037901,\n",
            " 'Loss/total_loss': 1.2822707,\n",
            " 'learning_rate': 0.014666351}\n",
            "INFO:tensorflow:Step 200 per-step time 2.054s\n",
            "I0328 15:56:33.891088 140463426705216 model_lib_v2.py:705] Step 200 per-step time 2.054s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.39202315,\n",
            " 'Loss/localization_loss': 0.31716377,\n",
            " 'Loss/regularization_loss': 0.30505523,\n",
            " 'Loss/total_loss': 1.0142422,\n",
            " 'learning_rate': 0.0159997}\n",
            "I0328 15:56:33.891554 140463426705216 model_lib_v2.py:708] {'Loss/classification_loss': 0.39202315,\n",
            " 'Loss/localization_loss': 0.31716377,\n",
            " 'Loss/regularization_loss': 0.30505523,\n",
            " 'Loss/total_loss': 1.0142422,\n",
            " 'learning_rate': 0.0159997}\n",
            "INFO:tensorflow:Step 300 per-step time 1.878s\n",
            "I0328 15:59:41.734329 140463426705216 model_lib_v2.py:705] Step 300 per-step time 1.878s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.3218673,\n",
            " 'Loss/localization_loss': 0.23406667,\n",
            " 'Loss/regularization_loss': 0.3048873,\n",
            " 'Loss/total_loss': 0.86082125,\n",
            " 'learning_rate': 0.01733305}\n",
            "I0328 15:59:41.734776 140463426705216 model_lib_v2.py:708] {'Loss/classification_loss': 0.3218673,\n",
            " 'Loss/localization_loss': 0.23406667,\n",
            " 'Loss/regularization_loss': 0.3048873,\n",
            " 'Loss/total_loss': 0.86082125,\n",
            " 'learning_rate': 0.01733305}\n",
            "INFO:tensorflow:Step 400 per-step time 1.943s\n",
            "I0328 16:02:56.066343 140463426705216 model_lib_v2.py:705] Step 400 per-step time 1.943s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.27120194,\n",
            " 'Loss/localization_loss': 0.25336838,\n",
            " 'Loss/regularization_loss': 0.30429393,\n",
            " 'Loss/total_loss': 0.8288642,\n",
            " 'learning_rate': 0.0186664}\n",
            "I0328 16:02:56.066781 140463426705216 model_lib_v2.py:708] {'Loss/classification_loss': 0.27120194,\n",
            " 'Loss/localization_loss': 0.25336838,\n",
            " 'Loss/regularization_loss': 0.30429393,\n",
            " 'Loss/total_loss': 0.8288642,\n",
            " 'learning_rate': 0.0186664}\n",
            "INFO:tensorflow:Step 500 per-step time 1.997s\n",
            "I0328 16:06:15.764414 140463426705216 model_lib_v2.py:705] Step 500 per-step time 1.997s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.21138626,\n",
            " 'Loss/localization_loss': 0.18711253,\n",
            " 'Loss/regularization_loss': 0.30370408,\n",
            " 'Loss/total_loss': 0.70220286,\n",
            " 'learning_rate': 0.01999975}\n",
            "I0328 16:06:15.764826 140463426705216 model_lib_v2.py:708] {'Loss/classification_loss': 0.21138626,\n",
            " 'Loss/localization_loss': 0.18711253,\n",
            " 'Loss/regularization_loss': 0.30370408,\n",
            " 'Loss/total_loss': 0.70220286,\n",
            " 'learning_rate': 0.01999975}\n",
            "INFO:tensorflow:Step 600 per-step time 1.798s\n",
            "I0328 16:09:15.601081 140463426705216 model_lib_v2.py:705] Step 600 per-step time 1.798s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.26877153,\n",
            " 'Loss/localization_loss': 0.1892509,\n",
            " 'Loss/regularization_loss': 0.30306208,\n",
            " 'Loss/total_loss': 0.7610845,\n",
            " 'learning_rate': 0.0213331}\n",
            "I0328 16:09:15.601551 140463426705216 model_lib_v2.py:708] {'Loss/classification_loss': 0.26877153,\n",
            " 'Loss/localization_loss': 0.1892509,\n",
            " 'Loss/regularization_loss': 0.30306208,\n",
            " 'Loss/total_loss': 0.7610845,\n",
            " 'learning_rate': 0.0213331}\n",
            "INFO:tensorflow:Step 700 per-step time 1.935s\n",
            "I0328 16:12:29.084328 140463426705216 model_lib_v2.py:705] Step 700 per-step time 1.935s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.1664688,\n",
            " 'Loss/localization_loss': 0.09671594,\n",
            " 'Loss/regularization_loss': 0.30176708,\n",
            " 'Loss/total_loss': 0.56495184,\n",
            " 'learning_rate': 0.02266645}\n",
            "I0328 16:12:29.084769 140463426705216 model_lib_v2.py:708] {'Loss/classification_loss': 0.1664688,\n",
            " 'Loss/localization_loss': 0.09671594,\n",
            " 'Loss/regularization_loss': 0.30176708,\n",
            " 'Loss/total_loss': 0.56495184,\n",
            " 'learning_rate': 0.02266645}\n",
            "INFO:tensorflow:Step 800 per-step time 1.875s\n",
            "I0328 16:15:36.569536 140463426705216 model_lib_v2.py:705] Step 800 per-step time 1.875s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.119966485,\n",
            " 'Loss/localization_loss': 0.114837565,\n",
            " 'Loss/regularization_loss': 0.30104697,\n",
            " 'Loss/total_loss': 0.535851,\n",
            " 'learning_rate': 0.023999799}\n",
            "I0328 16:15:36.569966 140463426705216 model_lib_v2.py:708] {'Loss/classification_loss': 0.119966485,\n",
            " 'Loss/localization_loss': 0.114837565,\n",
            " 'Loss/regularization_loss': 0.30104697,\n",
            " 'Loss/total_loss': 0.535851,\n",
            " 'learning_rate': 0.023999799}\n",
            "INFO:tensorflow:Step 900 per-step time 1.903s\n",
            "I0328 16:18:46.888694 140463426705216 model_lib_v2.py:705] Step 900 per-step time 1.903s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.26513007,\n",
            " 'Loss/localization_loss': 0.112810664,\n",
            " 'Loss/regularization_loss': 0.29917186,\n",
            " 'Loss/total_loss': 0.67711264,\n",
            " 'learning_rate': 0.025333151}\n",
            "I0328 16:18:46.889112 140463426705216 model_lib_v2.py:708] {'Loss/classification_loss': 0.26513007,\n",
            " 'Loss/localization_loss': 0.112810664,\n",
            " 'Loss/regularization_loss': 0.29917186,\n",
            " 'Loss/total_loss': 0.67711264,\n",
            " 'learning_rate': 0.025333151}\n",
            "INFO:tensorflow:Step 1000 per-step time 1.815s\n",
            "I0328 16:21:48.407191 140463426705216 model_lib_v2.py:705] Step 1000 per-step time 1.815s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.18187025,\n",
            " 'Loss/localization_loss': 0.11648681,\n",
            " 'Loss/regularization_loss': 0.29757637,\n",
            " 'Loss/total_loss': 0.59593344,\n",
            " 'learning_rate': 0.0266665}\n",
            "I0328 16:21:48.407814 140463426705216 model_lib_v2.py:708] {'Loss/classification_loss': 0.18187025,\n",
            " 'Loss/localization_loss': 0.11648681,\n",
            " 'Loss/regularization_loss': 0.29757637,\n",
            " 'Loss/total_loss': 0.59593344,\n",
            " 'learning_rate': 0.0266665}\n",
            "INFO:tensorflow:Step 1100 per-step time 1.912s\n",
            "I0328 16:24:59.618461 140463426705216 model_lib_v2.py:705] Step 1100 per-step time 1.912s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.113489404,\n",
            " 'Loss/localization_loss': 0.081383124,\n",
            " 'Loss/regularization_loss': 0.2949321,\n",
            " 'Loss/total_loss': 0.48980463,\n",
            " 'learning_rate': 0.02799985}\n",
            "I0328 16:24:59.623463 140463426705216 model_lib_v2.py:708] {'Loss/classification_loss': 0.113489404,\n",
            " 'Loss/localization_loss': 0.081383124,\n",
            " 'Loss/regularization_loss': 0.2949321,\n",
            " 'Loss/total_loss': 0.48980463,\n",
            " 'learning_rate': 0.02799985}\n",
            "INFO:tensorflow:Step 1200 per-step time 1.956s\n",
            "I0328 16:28:15.124820 140463426705216 model_lib_v2.py:705] Step 1200 per-step time 1.956s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.20107247,\n",
            " 'Loss/localization_loss': 0.15994306,\n",
            " 'Loss/regularization_loss': 0.2922367,\n",
            " 'Loss/total_loss': 0.6532522,\n",
            " 'learning_rate': 0.0293332}\n",
            "I0328 16:28:15.125226 140463426705216 model_lib_v2.py:708] {'Loss/classification_loss': 0.20107247,\n",
            " 'Loss/localization_loss': 0.15994306,\n",
            " 'Loss/regularization_loss': 0.2922367,\n",
            " 'Loss/total_loss': 0.6532522,\n",
            " 'learning_rate': 0.0293332}\n",
            "INFO:tensorflow:Step 1300 per-step time 1.799s\n",
            "I0328 16:31:15.064522 140463426705216 model_lib_v2.py:705] Step 1300 per-step time 1.799s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.12689774,\n",
            " 'Loss/localization_loss': 0.065844014,\n",
            " 'Loss/regularization_loss': 0.28852794,\n",
            " 'Loss/total_loss': 0.48126966,\n",
            " 'learning_rate': 0.03066655}\n",
            "I0328 16:31:15.064949 140463426705216 model_lib_v2.py:708] {'Loss/classification_loss': 0.12689774,\n",
            " 'Loss/localization_loss': 0.065844014,\n",
            " 'Loss/regularization_loss': 0.28852794,\n",
            " 'Loss/total_loss': 0.48126966,\n",
            " 'learning_rate': 0.03066655}\n",
            "INFO:tensorflow:Step 1400 per-step time 2.056s\n",
            "I0328 16:34:40.691511 140463426705216 model_lib_v2.py:705] Step 1400 per-step time 2.056s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.13152172,\n",
            " 'Loss/localization_loss': 0.07032379,\n",
            " 'Loss/regularization_loss': 0.2840888,\n",
            " 'Loss/total_loss': 0.4859343,\n",
            " 'learning_rate': 0.0319999}\n",
            "I0328 16:34:40.694593 140463426705216 model_lib_v2.py:708] {'Loss/classification_loss': 0.13152172,\n",
            " 'Loss/localization_loss': 0.07032379,\n",
            " 'Loss/regularization_loss': 0.2840888,\n",
            " 'Loss/total_loss': 0.4859343,\n",
            " 'learning_rate': 0.0319999}\n",
            "INFO:tensorflow:Step 1500 per-step time 1.896s\n",
            "I0328 16:37:50.239658 140463426705216 model_lib_v2.py:705] Step 1500 per-step time 1.896s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.092581436,\n",
            " 'Loss/localization_loss': 0.052154437,\n",
            " 'Loss/regularization_loss': 0.27999228,\n",
            " 'Loss/total_loss': 0.42472816,\n",
            " 'learning_rate': 0.03333325}\n",
            "I0328 16:37:50.240123 140463426705216 model_lib_v2.py:708] {'Loss/classification_loss': 0.092581436,\n",
            " 'Loss/localization_loss': 0.052154437,\n",
            " 'Loss/regularization_loss': 0.27999228,\n",
            " 'Loss/total_loss': 0.42472816,\n",
            " 'learning_rate': 0.03333325}\n",
            "INFO:tensorflow:Step 1600 per-step time 1.982s\n",
            "I0328 16:41:08.514113 140463426705216 model_lib_v2.py:705] Step 1600 per-step time 1.982s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.12717928,\n",
            " 'Loss/localization_loss': 0.13443619,\n",
            " 'Loss/regularization_loss': 0.27615058,\n",
            " 'Loss/total_loss': 0.53776604,\n",
            " 'learning_rate': 0.034666598}\n",
            "I0328 16:41:08.515254 140463426705216 model_lib_v2.py:708] {'Loss/classification_loss': 0.12717928,\n",
            " 'Loss/localization_loss': 0.13443619,\n",
            " 'Loss/regularization_loss': 0.27615058,\n",
            " 'Loss/total_loss': 0.53776604,\n",
            " 'learning_rate': 0.034666598}\n",
            "INFO:tensorflow:Step 1700 per-step time 1.732s\n",
            "I0328 16:44:01.665440 140463426705216 model_lib_v2.py:705] Step 1700 per-step time 1.732s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.17441148,\n",
            " 'Loss/localization_loss': 0.043029644,\n",
            " 'Loss/regularization_loss': 0.2720377,\n",
            " 'Loss/total_loss': 0.48947883,\n",
            " 'learning_rate': 0.03599995}\n",
            "I0328 16:44:01.665862 140463426705216 model_lib_v2.py:708] {'Loss/classification_loss': 0.17441148,\n",
            " 'Loss/localization_loss': 0.043029644,\n",
            " 'Loss/regularization_loss': 0.2720377,\n",
            " 'Loss/total_loss': 0.48947883,\n",
            " 'learning_rate': 0.03599995}\n",
            "INFO:tensorflow:Step 1800 per-step time 1.940s\n",
            "I0328 16:47:15.639697 140463426705216 model_lib_v2.py:705] Step 1800 per-step time 1.940s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.09796768,\n",
            " 'Loss/localization_loss': 0.056458764,\n",
            " 'Loss/regularization_loss': 0.26816595,\n",
            " 'Loss/total_loss': 0.4225924,\n",
            " 'learning_rate': 0.037333302}\n",
            "I0328 16:47:15.640155 140463426705216 model_lib_v2.py:708] {'Loss/classification_loss': 0.09796768,\n",
            " 'Loss/localization_loss': 0.056458764,\n",
            " 'Loss/regularization_loss': 0.26816595,\n",
            " 'Loss/total_loss': 0.4225924,\n",
            " 'learning_rate': 0.037333302}\n",
            "INFO:tensorflow:Step 1900 per-step time 1.827s\n",
            "I0328 16:50:18.319817 140463426705216 model_lib_v2.py:705] Step 1900 per-step time 1.827s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.13901564,\n",
            " 'Loss/localization_loss': 0.07237063,\n",
            " 'Loss/regularization_loss': 0.26393694,\n",
            " 'Loss/total_loss': 0.4753232,\n",
            " 'learning_rate': 0.03866665}\n",
            "I0328 16:50:18.321718 140463426705216 model_lib_v2.py:708] {'Loss/classification_loss': 0.13901564,\n",
            " 'Loss/localization_loss': 0.07237063,\n",
            " 'Loss/regularization_loss': 0.26393694,\n",
            " 'Loss/total_loss': 0.4753232,\n",
            " 'learning_rate': 0.03866665}\n",
            "INFO:tensorflow:Step 2000 per-step time 1.986s\n",
            "I0328 16:53:36.907529 140463426705216 model_lib_v2.py:705] Step 2000 per-step time 1.986s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.10327144,\n",
            " 'Loss/localization_loss': 0.06835082,\n",
            " 'Loss/regularization_loss': 0.26095405,\n",
            " 'Loss/total_loss': 0.43257633,\n",
            " 'learning_rate': nan}\n",
            "I0328 16:53:36.907993 140463426705216 model_lib_v2.py:708] {'Loss/classification_loss': 0.10327144,\n",
            " 'Loss/localization_loss': 0.06835082,\n",
            " 'Loss/regularization_loss': 0.26095405,\n",
            " 'Loss/total_loss': 0.43257633,\n",
            " 'learning_rate': nan}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "TlRqjT4AFOhv",
        "outputId": "a77528bd-f60a-4846-cf1a-f2b7eb8d3513"
      },
      "source": [
        "pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/training_demo'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeI2URnR9zhw",
        "outputId": "5f6e75ff-2b81-4363-af4f-4b8e18d699b6"
      },
      "source": [
        "!python exporter_main_v2.py --input_type image_tensor --pipeline_config_path /content/training_data/models/my_ssd_resnet101_v1_fpn/pipeline.config --trained_checkpoint_dir /content/training_data/models/my_ssd_resnet101_v1_fpn --output_directory /content/training_data/exported_models/my_model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-03-28 16:54:39.388030: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-28 16:54:39.388422: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-28 16:54:39.388457: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-28 16:54:48.690358: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
            "W0328 16:54:48.828422 140460866889536 deprecation.py:350] From /usr/local/lib/python3.9/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/autograph/impl/api.py:458: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
            "Instead of:\n",
            "results = tf.map_fn(fn, elems, back_prop=False)\n",
            "Use:\n",
            "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
            "W0328 16:54:48.950875 140460866889536 deprecation.py:623] From /usr/local/lib/python3.9/dist-packages/tensorflow/python/autograph/impl/api.py:458: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
            "Instead of:\n",
            "results = tf.map_fn(fn, elems, back_prop=False)\n",
            "Use:\n",
            "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
            "I0328 16:54:58.892333 140460866889536 api.py:459] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n",
            "I0328 16:55:12.749636 140460866889536 api.py:459] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n",
            "I0328 16:55:21.047641 140460866889536 api.py:459] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7fbf0c0f33d0>, because it is not built.\n",
            "W0328 16:55:23.654704 140460866889536 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7fbf0c0f33d0>, because it is not built.\n",
            "W0328 16:56:03.673440 140460866889536 save.py:271] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalClassHead_layer_call_fn while saving (showing 5 of 329). These functions will not be directly callable after loading.\n",
            "INFO:tensorflow:Assets written to: /content/training_data/exported_models/my_model/saved_model/assets\n",
            "I0328 16:56:17.096745 140460866889536 builder_impl.py:797] Assets written to: /content/training_data/exported_models/my_model/saved_model/assets\n",
            "INFO:tensorflow:Writing pipeline config file to /content/training_data/exported_models/my_model/pipeline.config\n",
            "I0328 16:56:19.583348 140460866889536 config_util.py:253] Writing pipeline config file to /content/training_data/exported_models/my_model/pipeline.config\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/exported_model.zip /content/training_data/exported_models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THEHtebxJ3j3",
        "outputId": "10dc71bc-c716-462b-d356-427e2988bc13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/training_data/exported_models/ (stored 0%)\n",
            "  adding: content/training_data/exported_models/my_model/ (stored 0%)\n",
            "  adding: content/training_data/exported_models/my_model/saved_model/ (stored 0%)\n",
            "  adding: content/training_data/exported_models/my_model/saved_model/assets/ (stored 0%)\n",
            "  adding: content/training_data/exported_models/my_model/saved_model/saved_model.pb (deflated 93%)\n",
            "  adding: content/training_data/exported_models/my_model/saved_model/fingerprint.pb (stored 0%)\n",
            "  adding: content/training_data/exported_models/my_model/saved_model/variables/ (stored 0%)\n",
            "  adding: content/training_data/exported_models/my_model/saved_model/variables/variables.index (deflated 81%)\n",
            "  adding: content/training_data/exported_models/my_model/saved_model/variables/variables.data-00000-of-00001 (deflated 7%)\n",
            "  adding: content/training_data/exported_models/my_model/checkpoint/ (stored 0%)\n",
            "  adding: content/training_data/exported_models/my_model/checkpoint/ckpt-0.index (deflated 82%)\n",
            "  adding: content/training_data/exported_models/my_model/checkpoint/checkpoint (deflated 41%)\n",
            "  adding: content/training_data/exported_models/my_model/checkpoint/ckpt-0.data-00000-of-00001 (deflated 7%)\n",
            "  adding: content/training_data/exported_models/my_model/pipeline.config (deflated 68%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/exported_model.zip\")"
      ],
      "metadata": {
        "id": "2JoXYqMaMQbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIIKwpxtGAhK"
      },
      "source": [
        "Inferencing My Trained Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "id": "spZJ4ms3FqRT",
        "outputId": "07e2878e-e280-4eff-94dc-9034e4b93ec7"
      },
      "source": [
        "\"\"\"\n",
        "Object Detection (On Image) From TF2 Saved Model\n",
        "=====================================\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'    # Suppress TensorFlow logging (1)\n",
        "import pathlib\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import argparse\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Enable GPU dynamic memory allocation\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "for gpu in gpus:\n",
        "    tf.config.experimental.set_memory_growth(gpu, True)\n",
        "\n",
        "# PROVIDE PATH TO IMAGE DIRECTORY\n",
        "IMAGE_PATHS = '/content/training_data/images/test/1.jpeg'\n",
        "\n",
        "\n",
        "# PROVIDE PATH TO MODEL DIRECTORY\n",
        "PATH_TO_MODEL_DIR = '/content/training_data/exported_models/my_model'\n",
        "\n",
        "# PROVIDE PATH TO LABEL MAP\n",
        "PATH_TO_LABELS = '/content/training_data/annotations/label_map.pbtxt'\n",
        "\n",
        "# PROVIDE THE MINIMUM CONFIDENCE THRESHOLD\n",
        "MIN_CONF_THRESH = float(0.60)\n",
        "\n",
        "# LOAD THE MODEL\n",
        "\n",
        "import time\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "\n",
        "PATH_TO_SAVED_MODEL = PATH_TO_MODEL_DIR + \"/saved_model\"\n",
        "\n",
        "print('Loading model...', end='')\n",
        "start_time = time.time()\n",
        "\n",
        "# LOAD SAVED MODEL AND BUILD DETECTION FUNCTION\n",
        "detect_fn = tf.saved_model.load(PATH_TO_SAVED_MODEL)\n",
        "\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "print('Done! Took {} seconds'.format(elapsed_time))\n",
        "\n",
        "# LOAD LABEL MAP DATA FOR PLOTTING\n",
        "\n",
        "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS,\n",
        "                                                                    use_display_name=True)\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')   # Suppress Matplotlib warnings\n",
        "\n",
        "def load_image_into_numpy_array(path):\n",
        "    \"\"\"Load an image from file into a numpy array.\n",
        "    Puts image into numpy array to feed into tensorflow graph.\n",
        "    Note that by convention we put it into a numpy array with shape\n",
        "    (height, width, channels), where channels=3 for RGB.\n",
        "    Args:\n",
        "      path: the file path to the image\n",
        "    Returns:\n",
        "      uint8 numpy array with shape (img_height, img_width, 3)\n",
        "    \"\"\"\n",
        "    return np.array(Image.open(path))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print('Running inference for {}... '.format(IMAGE_PATHS), end='')\n",
        "\n",
        "image = cv2.imread(IMAGE_PATHS)\n",
        "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "image_expanded = np.expand_dims(image_rgb, axis=0)\n",
        "\n",
        "# The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
        "input_tensor = tf.convert_to_tensor(image)\n",
        "# The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
        "input_tensor = input_tensor[tf.newaxis, ...]\n",
        "\n",
        "# input_tensor = np.expand_dims(image_np, 0)\n",
        "detections = detect_fn(input_tensor)\n",
        "\n",
        "# All outputs are batches tensors.\n",
        "# Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
        "# We're only interested in the first num_detections.\n",
        "num_detections = int(detections.pop('num_detections'))\n",
        "detections = {key: value[0, :num_detections].numpy()\n",
        "               for key, value in detections.items()}\n",
        "detections['num_detections'] = num_detections\n",
        "\n",
        "# detection_classes should be ints.\n",
        "detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "image_with_detections = image.copy()\n",
        "\n",
        "# SET MIN_SCORE_THRESH BASED ON YOU MINIMUM THRESHOLD FOR DETECTIONS\n",
        "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "      image_with_detections,\n",
        "      detections['detection_boxes'],\n",
        "      detections['detection_classes'],\n",
        "      detections['detection_scores'],\n",
        "      category_index,\n",
        "      use_normalized_coordinates=True,\n",
        "      max_boxes_to_draw=200,\n",
        "      min_score_thresh=0.5,\n",
        "      agnostic_mode=False)\n",
        "\n",
        "print('Done')\n",
        "# DISPLAYS OUTPUT IMAGE\n",
        "cv2_imshow(image_with_detections)\n",
        "# CLOSES WINDOW ONCE KEY IS PRESSED\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model...Done! Took 23.779768705368042 seconds\n",
            "Running inference for /content/training_data/images/test/1.jpeg... Done\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=225x225 at 0x7FF7ADF94700>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('hello world')"
      ],
      "metadata": {
        "id": "guV8Xczbd0nc",
        "outputId": "2410e1ba-7ecc-46de-c290-a3200e2bbc30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello world\n"
          ]
        }
      ]
    }
  ]
}